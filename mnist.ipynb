{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGIT RECOGNIZING - MNIST DATAASET (No pytorch/tf, just NUMPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE MNIST DATASET WAS DOWNLOADED FROM KAGGLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv') #MNIST DATASET from kaggle\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #we have 42000 images and 785 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 42000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.iloc[:,1:].values.T  #extracting the pixel value \n",
    "y = data.iloc[:,0].values.T   #extracting the labels in the first column\n",
    "m, n = data.shape\n",
    "print(x.shape)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def image(a):\n",
    "    a = np.random.randint(0, m)\n",
    "    plt.imshow(x[:, a].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Label : {}\".format(y[a]))\n",
    "    plt.show()\n",
    "#random image along with its label\n",
    "img = image(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters() :\n",
    "    W1 = np.random.randn(10,784) - 0.5   #adding bias to the wieghts\n",
    "    W2 = np.random.randn(10,10) - 0.5\n",
    "    b1 = np.random.randn(10,1) - 0.5\n",
    "    b2 = np.random.randn(10,1) - 0.5\n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTIVATION FUNCTIONS \n",
    " \n",
    "def RELU(L):\n",
    "    return np.maximum(0,x) #rectified linear unit\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0) #softmax function\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_pass(L1,A1,L2,A2) :\n",
    "    L1 = np.dot(W1, x) + b1 #first layer\n",
    "    A1 = RELU(L1) #activation function\n",
    "    L2 = np.dot(W2,A1) + b2 #second layer\n",
    "    A2 = softmax(L2) #activation function\n",
    "    return L1,A1,L2,A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def back_pass( dL2, dW2, db2, dL1, dW1, db1,x,y) :\n",
    "    dL2 = A2 - y #error in the second layer\n",
    "    dW2 = np.dot(dL2, A1.T)/m #gradient of the weights in the second layer\n",
    "    db2 = np.sum(dL2, axis=1, keepdims=True)/m #gradient of the bias in the second layer\n",
    "    dL1 = np.dot(W2, dL2) #error in the first layer\n",
    "    dW1 = np.dot(dL1, x.T)/m #gradient of the weights in the first layer\n",
    "    db1 = np.sum(dL1, axis=1, keepdims=True)/m #gradient of the bias in the first\n",
    "    return dL2 ,dW2, db2,dL1 , dW1, db1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha) :\n",
    "    #alpha = 0.01\n",
    "    W1 = W1 - alpha*dW1    #aplha is the learning rate\n",
    "    W2 = W2 - alpha*dW2\n",
    "    b1 = b1 - alpha*db1\n",
    "    b2 = b2 - alpha*db2\n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2) :\n",
    "    return np.argmax(A2, 0) #returns the index of the maximum value in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, y) :\n",
    "    predictions = get_predictions(A2)\n",
    "    return np.sum(predictions == y)/m #returns the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def one_hot_encoding(y) :\\n    one_hot = np.zeros((y.size, y.max()+1))\\n    one_hot[np.arange(y.size), y] = 1\\n    return one_hot.T'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def one_hot_encoding(y) :\n",
    "    one_hot = np.zeros((y.size, y.max()+1))\n",
    "    one_hot[np.arange(y.size), y] = 1\n",
    "    return one_hot.T\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parameters() missing 4 required positional arguments: 'W1', 'W2', 'b1', and 'b2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[304], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m#if i % 100 == 0:\u001b[39;00m\n\u001b[0;32m     11\u001b[0m            \u001b[38;5;66;03m# print(f\"accuracy is {accuracy}\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, b1, b2\n\u001b[1;32m---> 14\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n\u001b[0;32m     16\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m get_accuracy(predictions, y)\n",
      "Cell \u001b[1;32mIn[304], line 2\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(x, y, alpha, iterations)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_descent\u001b[39m(x, y, alpha, iterations):\n\u001b[1;32m----> 2\u001b[0m     W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n",
      "\u001b[1;31mTypeError\u001b[0m: parameters() missing 4 required positional arguments: 'W1', 'W2', 'b1', and 'b2'"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x, y, alpha, iterations):\n",
    "    W1, W2, b1, b2 = parameters()\n",
    "    iterations = 1000\n",
    "    for i in range(iterations):\n",
    "        L1, A1, L2, A2 = for_pass(W1, W2, b1, b2)\n",
    "        dL2, dW2, db2, dL1, dW1, db1 = back_pass(L2, y, W2, A1, x)\n",
    "        W1, W2, b1, b2 = weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
    "        predictions = get_predictions(A2, 0)\n",
    "        accuracy = get_accuracy(predictions, y)\n",
    "        #if i % 100 == 0:\n",
    "           # print(f\"accuracy is {accuracy}\")\n",
    "    return W1, W2, b1, b2\n",
    "            \n",
    "W1, W2, b1, b2 = gradient_descent(x, y, 0.01, 1000)\n",
    "predictions = get_predictions(A2)\n",
    "accuracy = get_accuracy(predictions, y)\n",
    "print(f\"accuracy is {accuracy}\") \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10,10) and (784,42000) not aligned: 10 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[308], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, b1, b2, A2\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m W1, W2, b1, b2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Final predictions and accuracy\u001b[39;00m\n\u001b[0;32m     25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n",
      "Cell \u001b[1;32mIn[308], line 5\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(x, y, alpha, iterations)\u001b[0m\n\u001b[0;32m      2\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m parameters()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mfor_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     dL2, dW2, db2, dL1, dW1, db1 \u001b[38;5;241m=\u001b[39m back_pass(L2, y, W2, A1, x,)\n",
      "Cell \u001b[1;32mIn[274], line 4\u001b[0m, in \u001b[0;36mfor_pass\u001b[1;34m(L1, A1, L2, A2)\u001b[0m\n\u001b[0;32m      2\u001b[0m L1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W1, x) \u001b[38;5;241m+\u001b[39m b1 \u001b[38;5;66;03m#first layer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m A1 \u001b[38;5;241m=\u001b[39m RELU(L1) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m L2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mA1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b2 \u001b[38;5;66;03m#second layer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m A2 \u001b[38;5;241m=\u001b[39m softmax(L2) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L1,A1,L2,A2\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,10) and (784,42000) not aligned: 10 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x, y, alpha, iterations):\n",
    "    W1, W2, b1, b2 = parameters()\n",
    "    for i in range(iterations):\n",
    "        # Forward pass\n",
    "        L1, A1, L2, A2 = for_pass( W1, W2, b1, b2)\n",
    "        \n",
    "        # Backward pass\n",
    "        dL2, dW2, db2, dL1, dW1, db1 = back_pass(L2, y, W2, A1, x,)\n",
    "        \n",
    "        # Update weights\n",
    "        W1, W2, b1, b2 = weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
    "        \n",
    "        # Monitor training progress\n",
    "        predictions = get_predictions(A2)\n",
    "        accuracy = get_accuracy(predictions, y)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Accuracy is {accuracy:.2f}\")\n",
    "    \n",
    "    return W1, W2, b1, b2, A2\n",
    "\n",
    "# Example usage:\n",
    "W1, W2, b1, b2, A2 = gradient_descent(x, y, 0.01, 1000)\n",
    "\n",
    "# Final predictions and accuracy\n",
    "predictions = get_predictions(A2)\n",
    "accuracy = get_accuracy(predictions, y)\n",
    "print(f\"Final accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
