{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGIT RECOGNIZING - MNIST DATAASET (No pytorch/tf, just NUMPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE MNIST DATASET WAS DOWNLOADED FROM KAGGLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv') #MNIST DATASET from kaggle\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #we have 42000 images and 785 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data) #shuffling the data\n",
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 42000)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "x = data[:, 1:].T/255  # extracting the pixel value \n",
    "y = data[:, 0]   # extracting the labels in the first column\n",
    "m, n = data.shape\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGIT RECOGNIZING - MNIST DATAASET (No pytorch/tf, just NUMPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def image(a):\n",
    "    a = np.random.randint(0, m)\n",
    "    plt.imshow(x[:, a].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Label : {}\".format(y[a]))\n",
    "    plt.show()\n",
    "#random image along with its label\n",
    "img = image(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 42000)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "def one_hot(y):\n",
    "    one_hot_y = np.zeros((10, y.shape[0]))\n",
    "    for i in range(y.shape[0]):\n",
    "        one_hot_y[y[i], i] = 1\n",
    "    return one_hot_y\n",
    "one_hot_y = one_hot(y)\n",
    "one_hot_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 784), (10, 10), (10, 42000), (10, 42000))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def parameters() :\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W1 = np.random.randn(10, 784) - 0.5   # adding bias to the weights\n",
    "        self.W2 = np.random.randn(10, 10) - 0.5\n",
    "        self.b1 = np.random.randn(10,m) - 0.5\n",
    "        self.b2 = np.random.randn(10, m) - 0.5  \n",
    "        self.alpha  = 0.1    # learning rate\n",
    "params = Parameters()\n",
    "W1 = params.W1\n",
    "W2 = params.W2\n",
    "b1 = params.b1\n",
    "b2 = params.b2\n",
    "alpha = params.alpha\n",
    "        \n",
    "\n",
    "W1.shape, W2.shape, b1.shape, b2.shape  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTIVATION FUNCTIONS \n",
    " \n",
    "def RELU(L):\n",
    "    return np.maximum(0,x) #rectified linear unit\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0) #softmax function\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,10) (10,42000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     A2 \u001b[38;5;241m=\u001b[39m softmax(L2) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m L1, A1, L2, A2\n\u001b[1;32m----> 8\u001b[0m L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mfor_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m A1\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     10\u001b[0m x\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn[166], line 4\u001b[0m, in \u001b[0;36mfor_pass\u001b[1;34m(W1, W2, b1, b2, x)\u001b[0m\n\u001b[0;32m      2\u001b[0m L1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W1, x) \u001b[38;5;241m+\u001b[39m b1 \u001b[38;5;66;03m#first layer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m A1 \u001b[38;5;241m=\u001b[39m RELU(L1) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m L2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m \u001b[38;5;66;03m#second layer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m A2 \u001b[38;5;241m=\u001b[39m softmax(L2) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L1, A1, L2, A2\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,10) (10,42000) "
     ]
    }
   ],
   "source": [
    "def for_pass(W1, W2, b1, b2, x):\n",
    "    L1 = np.dot(W1, x) + b1 #first layer\n",
    "    A1 = RELU(L1) #activation function\n",
    "    L2 = np.dot(W2, ) + b2 #second layer\n",
    "    A2 = softmax(L2) #activation function\n",
    "    return L1, A1, L2, A2\n",
    "\n",
    "L1, A1, L2, A2 = for_pass(W1, W2, b1, b2, x)\n",
    "A1.shape\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_Relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def back_pass( dL2, dW2, db2, dL1, dW1, db1,x,y) :\n",
    "    one_hot_y = one_hot(y)\n",
    "    dL2 = A2 - one_hot_y #error in the second layer\n",
    "    dW2 = np.dot(dL2, A1.T)/m #gradient of the weights in the second layer\n",
    "    db2 = np.sum(dL2, axis=1, keepdims=True)/m #gradient of the bias in the second layer\n",
    "    dL1 = np.dot(W2, dL2).der_Relu(L1) #error in the first layer\n",
    "    dW1 = np.dot(dL1, x.T)/m #gradient of the weights in the first layer\n",
    "    db1 = np.sum(dL1, axis=1, keepdims=True)/m #gradient of the bias in the first\n",
    "    return dL2 ,dW2, db2,dL1 , dW1, db1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha) :\n",
    "    #alpha = 0.01\n",
    "    W1 = W1 - alpha*dW1    #aplha is the learning rate\n",
    "    W2 = W2 - alpha*dW2\n",
    "    b1 = b1 - alpha*db1\n",
    "    b2 = b2 - alpha*db2\n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2) :\n",
    "    return np.argmax(A2, 0) #returns the index of the maximum value in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, y) :\n",
    "    predictions = get_predictions(A2)\n",
    "    return np.sum(predictions == y)/m #returns the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def one_hot_encoding(y) :\\n    one_hot = np.zeros((y.size, y.max()+1))\\n    one_hot[np.arange(y.size), y] = 1\\n    return one_hot.T'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def one_hot_encoding(y) :\n",
    "    one_hot = np.zeros((y.size, y.max()+1))\n",
    "    one_hot[np.arange(y.size), y] = 1\n",
    "    return one_hot.T\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10,10) and (784,42000) not aligned: 10 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m#if i % 100 == 0:\u001b[39;00m\n\u001b[0;32m     11\u001b[0m            \u001b[38;5;66;03m# print(f\"accuracy is {accuracy}\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, b1, b2\n\u001b[1;32m---> 14\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n\u001b[0;32m     16\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m get_accuracy(predictions, y)\n",
      "Cell \u001b[1;32mIn[153], line 5\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(x, y, alpha, iterations)\u001b[0m\n\u001b[0;32m      3\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m----> 5\u001b[0m     L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mfor_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     dL2, dW2, db2, dL1, dW1, db1 \u001b[38;5;241m=\u001b[39m back_pass(L2, y, W2, A1, x)\n\u001b[0;32m      7\u001b[0m     W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
      "Cell \u001b[1;32mIn[144], line 4\u001b[0m, in \u001b[0;36mfor_pass\u001b[1;34m(L1, A1, L2, A2, x)\u001b[0m\n\u001b[0;32m      2\u001b[0m L1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W1, x) \u001b[38;5;241m+\u001b[39m b1 \u001b[38;5;66;03m#first layer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m A1 \u001b[38;5;241m=\u001b[39m RELU(L1) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m L2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mA1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b2 \u001b[38;5;66;03m#second layer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m A2 \u001b[38;5;241m=\u001b[39m softmax(L2) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L1,A1,L2,A2\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,10) and (784,42000) not aligned: 10 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x, y, alpha, iterations):\n",
    "    W1, W2, b1, b2 = parameters()\n",
    "    iterations = 1000\n",
    "    for i in range(iterations):\n",
    "        L1, A1, L2, A2 = for_pass(W1, W2, b1, b2,x)\n",
    "        dL2, dW2, db2, dL1, dW1, db1 = back_pass(L2, y, W2, A1, x)\n",
    "        W1, W2, b1, b2 = weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
    "        predictions = get_predictions(A2, 0)\n",
    "        accuracy = get_accuracy(predictions, y)\n",
    "        #if i % 100 == 0:\n",
    "           # print(f\"accuracy is {accuracy}\")\n",
    "    return W1, W2, b1, b2\n",
    "            \n",
    "W1, W2, b1, b2 = gradient_descent(x, y, 0.05, 1000)\n",
    "predictions = get_predictions(A2)\n",
    "accuracy = get_accuracy(predictions, y)\n",
    "print(f\"accuracy is {accuracy}\") \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10,10) and (784,42000) not aligned: 10 (dim 1) != 784 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[308], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, b1, b2, A2\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m W1, W2, b1, b2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Final predictions and accuracy\u001b[39;00m\n\u001b[0;32m     25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n",
      "Cell \u001b[1;32mIn[308], line 5\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(x, y, alpha, iterations)\u001b[0m\n\u001b[0;32m      2\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m parameters()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mfor_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     dL2, dW2, db2, dL1, dW1, db1 \u001b[38;5;241m=\u001b[39m back_pass(L2, y, W2, A1, x,)\n",
      "Cell \u001b[1;32mIn[274], line 4\u001b[0m, in \u001b[0;36mfor_pass\u001b[1;34m(L1, A1, L2, A2)\u001b[0m\n\u001b[0;32m      2\u001b[0m L1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W1, x) \u001b[38;5;241m+\u001b[39m b1 \u001b[38;5;66;03m#first layer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m A1 \u001b[38;5;241m=\u001b[39m RELU(L1) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m L2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mA1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b2 \u001b[38;5;66;03m#second layer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m A2 \u001b[38;5;241m=\u001b[39m softmax(L2) \u001b[38;5;66;03m#activation function\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L1,A1,L2,A2\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,10) and (784,42000) not aligned: 10 (dim 1) != 784 (dim 0)"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x, y, alpha, iterations):\n",
    "    W1, W2, b1, b2 = parameters()\n",
    "    for i in range(iterations):\n",
    "        # Forward pass\n",
    "        L1, A1, L2, A2 = for_pass( W1, W2, b1, b2)\n",
    "        \n",
    "        # Backward pass\n",
    "        dL2, dW2, db2, dL1, dW1, db1 = back_pass(L2, y, W2, A1, x,)\n",
    "        \n",
    "        # Update weights\n",
    "        W1, W2, b1, b2 = weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
    "        \n",
    "        # Monitor training progress\n",
    "        predictions = get_predictions(A2)\n",
    "        accuracy = get_accuracy(predictions, y)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Accuracy is {accuracy:.2f}\")\n",
    "    \n",
    "    return W1, W2, b1, b2, A2\n",
    "\n",
    "# Example usage:\n",
    "W1, W2, b1, b2, A2 = gradient_descent(x, y, 0.05, 1000)\n",
    "\n",
    "# Final predictions and accuracy\n",
    "predictions = get_predictions(A2)\n",
    "accuracy = get_accuracy(predictions, y)\n",
    "print(f\"Final accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfwUlEQVR4nO3de3BU9fnH8c9yyXJLFgPkJgESQFC52ILEVC5RMoS0pQTpeJ2RtA4WDI5IvRRHQLBOlLbKaBGdVolW8EKHS9WKI2DC0AYsKGVoNU2YICBJgDjsQoCA5Pz+YNwfKwE8y26eJLxfM9+Z7DnfZ8+Tw5l8OLtnz3ocx3EEAEATa2PdAADg8kQAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABYdi9e7c8Ho9+//vfR+w5i4uL5fF4VFxcHLHnBJozAgiXjaKiInk8Hm3dutW6lSaTn58vj8dz3vHVV19Zt4jLWDvrBgBEz69+9StlZ2eHLHMcR9OmTVOfPn105ZVXGnUGEEBAq5aZmanMzMyQZZs2bdKxY8d01113GXUFnMFLcMBZTp48qblz52rYsGHy+Xzq3LmzRo0apY8//vi8Nc8995x69+6tjh07asyYMdq5c+c5c7744gv9/Oc/V3x8vDp06KDhw4frb3/7W9h9fvHFF9qzZ09YtcuXL5fH49Gdd94Z9vaBSCCAgLMEAgH9+c9/VlZWlp555hk98cQTOnjwoHJycrR9+/Zz5r/++ut6/vnnVVBQoNmzZ2vnzp26+eabVVNTE5zzn//8RzfccIM+//xz/eY3v9Ef/vAHde7cWXl5eVq1alVYfV599dW6++67XdedOnVK77zzjn70ox+pT58+YW0biBReggPOcsUVV2j37t2KiYkJLps6daoGDhyoF154Qa+88krI/IqKCpWXlwffSxk/frwyMjL0zDPP6Nlnn5UkPfDAA+rVq5f+9a9/yev1SpLuu+8+jRw5Uo8++qgmTZrURL+d9OGHH6q2tpaX39AscAYEnKVt27bB8GloaNDXX3+tb775RsOHD9enn356zvy8vLyQN/JHjBihjIwM/f3vf5ckff3119qwYYNuvfVWHTlyRIcOHdKhQ4dUW1urnJwclZeXh3UlmuM4YV2uvXz5crVv31633nqr61og0ggg4Dtee+01DRkyRB06dFC3bt3Uo0cPvf/++/L7/efM7d+//znLrrrqKu3evVvSmTMkx3E0Z84c9ejRI2TMmzdPknTgwIGo/j7fOnr0qNasWaOcnBx169atSbYJXAgvwQFneeONN5Sfn6+8vDw9/PDDSkhIUNu2bVVYWKhdu3a5fr6GhgZJ0kMPPaScnJxG5/Tr1++Sev6+Vq9ezdVvaFYIIOAsf/3rX5Wenq6VK1fK4/EEl397tvJd5eXl5yz73//+F3yDPz09XZLUvn37cz6P09SWLVumLl266Gc/+5lpH8C3eAkOOEvbtm0lnXmP5VtbtmxRaWlpo/NXr14d8h7OJ598oi1btig3N1eSlJCQoKysLL388suqqqo6p/7gwYNh9en2MuyDBw9q3bp1mjRpkjp16hTWNoFI4wwIl51XX31Va9euPWf5Aw88oJ/+9KdauXKlJk2apJ/85CeqrKzUSy+9pGuuuUZHjx49p6Zfv34aOXKkpk+frvr6ei1atEjdunXTI488EpyzePFijRw5UoMHD9bUqVOVnp6umpoalZaWat++ffr3v//t+ne4+uqrNWbMmO99IcLbb7+tb775hpff0KwQQLjsLFmypNHl+fn5ys/PV3V1tV5++WV9+OGHuuaaa/TGG29oxYoVjf6xv/vuu9WmTRstWrRIBw4c0IgRI/THP/5RycnJwTnXXHONtm7dqvnz56uoqEi1tbVKSEjQD37wA82dOzdav2aIZcuWKSEhwfxlQOBsHufs1xoAAGgivAcEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEw0u88BNTQ0aP/+/YqNjQ25FQoAoGVwHEdHjhxRSkqK2rQ5/3lOswug/fv3KzU11boNAMAl2rt3r3r27Hne9c3uJbjY2FjrFgAAEXCxv+dRC6DFixerT58+6tChgzIyMvTJJ598rzpedgOA1uFif8+jEkBvv/22Zs2apXnz5unTTz/V0KFDlZOT02RfvAUAaAGcKBgxYoRTUFAQfHz69GknJSXFKSwsvGit3+93JDEYDAajhQ+/33/Bv/cRPwM6efKktm3bFnLX3TZt2ig7O7vR71Spr69XIBAIGQCA1i/iAXTo0CGdPn1aiYmJIcsTExNVXV19zvzCwkL5fL7g4Ao4ALg8mF8FN3v2bPn9/uDYu3evdUsAgCYQ8c8Bde/eXW3btlVNTU3I8pqaGiUlJZ0z3+v1yuv1RroNAEAzF/EzoJiYGA0bNkzr168PLmtoaND69euVmZkZ6c0BAFqoqNwJYdasWZoyZYqGDx+uESNGaNGiRaqrq9MvfvGLaGwOANACRSWAbrvtNh08eFBz585VdXW1rrvuOq1du/acCxMAAJcvj+M4jnUTZwsEAvL5fNZtAAAukd/vV1xc3HnXm18FBwC4PBFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBExAPoiSeekMfjCRkDBw6M9GYAAC1cu2g86bXXXqt169b9/0baRWUzAIAWLCrJ0K5dOyUlJUXjqQEArURU3gMqLy9XSkqK0tPTddddd2nPnj3nnVtfX69AIBAyAACtX8QDKCMjQ0VFRVq7dq2WLFmiyspKjRo1SkeOHGl0fmFhoXw+X3CkpqZGuiUAQDPkcRzHieYGDh8+rN69e+vZZ5/VPffcc876+vp61dfXBx8HAgFCCABaAb/fr7i4uPOuj/rVAV27dtVVV12lioqKRtd7vV55vd5otwEAaGai/jmgo0ePateuXUpOTo72pgAALUjEA+ihhx5SSUmJdu/erX/+85+aNGmS2rZtqzvuuCPSmwIAtGARfwlu3759uuOOO1RbW6sePXpo5MiR2rx5s3r06BHpTQEAWrCoX4TgViAQkM/ns24DAHCJLnYRAveCAwCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCLqX0gHtHZ9+vRxXXPrrbe6rgnnJr2PPfaY65qm9Mtf/tJ1zdKlS6PQCSxwBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMHdsBG2uLg41zWTJ0+OQieR8/jjj7uu6datm+uacPZdOBzHaZLthGvJkiWua2JiYlzXvPzyy65rEH2cAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDhcZrZ3QoDgYB8Pp91Gy1WYmKi65pXX301rG0NGDDAdU16enpY24J04sQJ1zXr1q0La1v9+/d3XRPO8RCOjRs3uq7JysqKfCO4KL/ff8Eb73IGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwEQ76wYQWeHcRLJXr15hbSucG4uePn3adc3WrVtd1zSlRYsWua756quvXNecOnXKdc2WLVtc10jSnDlzXNfMnz8/rG3h8sUZEADABAEEADDhOoA2btyoCRMmKCUlRR6PR6tXrw5Z7ziO5s6dq+TkZHXs2FHZ2dkqLy+PVL8AgFbCdQDV1dVp6NChWrx4caPrFy5cqOeff14vvfSStmzZos6dOysnJyesL9MCALReri9CyM3NVW5ubqPrHMfRokWL9Pjjj2vixImSpNdff12JiYlavXq1br/99kvrFgDQakT0PaDKykpVV1crOzs7uMzn8ykjI0OlpaWN1tTX1ysQCIQMAEDrF9EAqq6uliQlJiaGLE9MTAyu+67CwkL5fL7gSE1NjWRLAIBmyvwquNmzZ8vv9wfH3r17rVsCADSBiAZQUlKSJKmmpiZkeU1NTXDdd3m9XsXFxYUMAEDrF9EASktLU1JSktavXx9cFggEtGXLFmVmZkZyUwCAFs71VXBHjx5VRUVF8HFlZaW2b9+u+Ph49erVSzNnztRvf/tb9e/fX2lpaZozZ45SUlKUl5cXyb4BAC2c6wDaunWrbrrppuDjWbNmSZKmTJmioqIiPfLII6qrq9O9996rw4cPa+TIkVq7dq06dOgQua4BAC2e6wDKysqS4zjnXe/xeLRgwQItWLDgkhpDeDZt2uS6ZsyYMWFtK5y6b775xnXNu+++67oGrVdtba11C4gQ86vgAACXJwIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACY9zoVtbGwgEAvL5fNZtAK1Cly5dwqrbsGGD65rhw4e7rgnn7ujhfLnltm3bXNfg0vn9/gt+yzVnQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEy0s24AQPQ89dRTYdWFc2PRcNx3332ua7ixaOvBGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAAT3IwUaCG6dOniuua6666LfCMRtGHDBusWYIgzIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACa4GSnQQtx0002ua0aNGhWFThr3l7/8xXXNnj17otAJWgrOgAAAJgggAIAJ1wG0ceNGTZgwQSkpKfJ4PFq9enXI+vz8fHk8npAxfvz4SPULAGglXAdQXV2dhg4dqsWLF593zvjx41VVVRUcb7755iU1CQBofVxfhJCbm6vc3NwLzvF6vUpKSgq7KQBA6xeV94CKi4uVkJCgAQMGaPr06aqtrT3v3Pr6egUCgZABAGj9Ih5A48eP1+uvv67169frmWeeUUlJiXJzc3X69OlG5xcWFsrn8wVHampqpFsCADRDEf8c0O233x78efDgwRoyZIj69u2r4uJijR079pz5s2fP1qxZs4KPA4EAIQQAl4GoX4adnp6u7t27q6KiotH1Xq9XcXFxIQMA0PpFPYD27dun2tpaJScnR3tTAIAWxPVLcEePHg05m6msrNT27dsVHx+v+Ph4zZ8/X5MnT1ZSUpJ27dqlRx55RP369VNOTk5EGwcAtGyuA2jr1q0h96T69v2bKVOmaMmSJdqxY4dee+01HT58WCkpKRo3bpyefPJJeb3eyHUNAGjxPI7jONZNnC0QCMjn81m3AURVOO91fveuI99HVlaW6xpJ+tOf/uS65sknn3Rds2/fPtc1aDn8fv8Fj3XuBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMBHxr+QGcHFPP/2065pw7mwd7s3ut2/f7rqGO1vDLc6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOBmpMBZOnXq5LomIyPDdc2kSZNc15w+fdp1zYsvvui6RpKWLFkSVh3gBmdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATHgcx3GsmzhbIBCQz+ezbgOXqbvvvtt1TVFRUeQbacSXX37puiYtLS0KnQDfj9/vV1xc3HnXcwYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARDvrBoDm5KmnnmqS7dTU1LiumThxYhQ6AexwBgQAMEEAAQBMuAqgwsJCXX/99YqNjVVCQoLy8vJUVlYWMufEiRMqKChQt27d1KVLF02ePDmslxsAAK2bqwAqKSlRQUGBNm/erI8++kinTp3SuHHjVFdXF5zz4IMP6t1339WKFStUUlKi/fv365Zbbol44wCAls3VRQhr164NeVxUVKSEhARt27ZNo0ePlt/v1yuvvKLly5fr5ptvliQtXbpUV199tTZv3qwbbrghcp0DAFq0S3oPyO/3S5Li4+MlSdu2bdOpU6eUnZ0dnDNw4ED16tVLpaWljT5HfX29AoFAyAAAtH5hB1BDQ4NmzpypG2+8UYMGDZIkVVdXKyYmRl27dg2Zm5iYqOrq6kafp7CwUD6fLzhSU1PDbQkA0IKEHUAFBQXauXOn3nrrrUtqYPbs2fL7/cGxd+/eS3o+AEDLENYHUWfMmKH33ntPGzduVM+ePYPLk5KSdPLkSR0+fDjkLKimpkZJSUmNPpfX65XX6w2nDQBAC+bqDMhxHM2YMUOrVq3Shg0blJaWFrJ+2LBhat++vdavXx9cVlZWpj179igzMzMyHQMAWgVXZ0AFBQVavny51qxZo9jY2OD7Oj6fTx07dpTP59M999yjWbNmKT4+XnFxcbr//vuVmZnJFXAAgBCuAmjJkiWSpKysrJDlS5cuVX5+viTpueeeU5s2bTR58mTV19crJydHL774YkSaBQC0Hh7HcRzrJs4WCATk8/ms20ALd+jQobDqrrjiCtc1Ho/Hdc2ECRNc17z//vuuawBLfr9fcXFx513PveAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACbC+kZUoClde+21rmsudAfeCwnnztbffk2JGxs2bHBdA7Q2nAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwc1I0aQGDRrkuuaDDz5wXdOuXXiH9oEDB1zXPPfcc65rjh8/7roGaG04AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCm5EibDExMa5r5syZ47rmyiuvdF0TruXLl7uuqaioiEInQOvHGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATHsdxHOsmzhYIBOTz+azbwPfQt29f1zXl5eVR6ORcx48fD6uuX79+rmuqqqrC2hbQ2vn9fsXFxZ13PWdAAAATBBAAwISrACosLNT111+v2NhYJSQkKC8vT2VlZSFzsrKy5PF4Qsa0adMi2jQAoOVzFUAlJSUqKCjQ5s2b9dFHH+nUqVMaN26c6urqQuZNnTpVVVVVwbFw4cKINg0AaPlcfSPq2rVrQx4XFRUpISFB27Zt0+jRo4PLO3XqpKSkpMh0CABolS7pPSC/3y9Jio+PD1m+bNkyde/eXYMGDdLs2bN17Nix8z5HfX29AoFAyAAAtH6uzoDO1tDQoJkzZ+rGG2/UoEGDgsvvvPNO9e7dWykpKdqxY4ceffRRlZWVaeXKlY0+T2FhoebPnx9uGwCAFirszwFNnz5dH3zwgTZt2qSePXued96GDRs0duxYVVRUNPq5kfr6etXX1wcfBwIBpaamhtMSmhifAzqDzwEBjbvY54DCOgOaMWOG3nvvPW3cuPGC4SNJGRkZknTeAPJ6vfJ6veG0AQBowVwFkOM4uv/++7Vq1SoVFxcrLS3tojXbt2+XJCUnJ4fVIACgdXIVQAUFBVq+fLnWrFmj2NhYVVdXS5J8Pp86duyoXbt2afny5frxj3+sbt26aceOHXrwwQc1evRoDRkyJCq/AACgZXIVQEuWLJF05sOmZ1u6dKny8/MVExOjdevWadGiRaqrq1NqaqomT56sxx9/PGINAwBaB9cvwV1IamqqSkpKLqkhAMDlIezLsIHa2lrXNXPnznVds2DBAtc1eXl5rmskrmgDmhI3IwUAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAi7K/kjpZAICCfz2fdBgDgEl3sK7k5AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiWYXQM3s1nQAgDBd7O95swugI0eOWLcAAIiAi/09b3Z3w25oaND+/fsVGxsrj8cTsi4QCCg1NVV79+694B1WWzv2wxnshzPYD2ewH85oDvvBcRwdOXJEKSkpatPm/Oc57Zqwp++lTZs26tmz5wXnxMXFXdYH2LfYD2ewH85gP5zBfjjDej98n6/VaXYvwQEALg8EEADARIsKIK/Xq3nz5snr9Vq3Yor9cAb74Qz2wxnshzNa0n5odhchAAAuDy3qDAgA0HoQQAAAEwQQAMAEAQQAMEEAAQBMtJgAWrx4sfr06aMOHTooIyNDn3zyiXVLTe6JJ56Qx+MJGQMHDrRuK+o2btyoCRMmKCUlRR6PR6tXrw5Z7ziO5s6dq+TkZHXs2FHZ2dkqLy+3aTaKLrYf8vPzzzk+xo8fb9NslBQWFur6669XbGysEhISlJeXp7KyspA5J06cUEFBgbp166YuXbpo8uTJqqmpMeo4Or7PfsjKyjrneJg2bZpRx41rEQH09ttva9asWZo3b54+/fRTDR06VDk5OTpw4IB1a03u2muvVVVVVXBs2rTJuqWoq6ur09ChQ7V48eJG1y9cuFDPP/+8XnrpJW3ZskWdO3dWTk6OTpw40cSdRtfF9oMkjR8/PuT4ePPNN5uww+grKSlRQUGBNm/erI8++kinTp3SuHHjVFdXF5zz4IMP6t1339WKFStUUlKi/fv365ZbbjHsOvK+z36QpKlTp4YcDwsXLjTq+DycFmDEiBFOQUFB8PHp06edlJQUp7Cw0LCrpjdv3jxn6NCh1m2YkuSsWrUq+LihocFJSkpyfve73wWXHT582PF6vc6bb75p0GHT+O5+cBzHmTJlijNx4kSTfqwcOHDAkeSUlJQ4jnPm3759+/bOihUrgnM+//xzR5JTWlpq1WbUfXc/OI7jjBkzxnnggQfsmvoemv0Z0MmTJ7Vt2zZlZ2cHl7Vp00bZ2dkqLS017MxGeXm5UlJSlJ6errvuukt79uyxbslUZWWlqqurQ44Pn8+njIyMy/L4KC4uVkJCggYMGKDp06ertrbWuqWo8vv9kqT4+HhJ0rZt23Tq1KmQ42HgwIHq1atXqz4evrsfvrVs2TJ1795dgwYN0uzZs3Xs2DGL9s6r2d0N+7sOHTqk06dPKzExMWR5YmKivvjiC6OubGRkZKioqEgDBgxQVVWV5s+fr1GjRmnnzp2KjY21bs9EdXW1JDV6fHy77nIxfvx43XLLLUpLS9OuXbv02GOPKTc3V6WlpWrbtq11exHX0NCgmTNn6sYbb9SgQYMknTkeYmJi1LVr15C5rfl4aGw/SNKdd96p3r17KyUlRTt27NCjjz6qsrIyrVy50rDbUM0+gPD/cnNzgz8PGTJEGRkZ6t27t9555x3dc889hp2hObj99tuDPw8ePFhDhgxR3759VVxcrLFjxxp2Fh0FBQXauXPnZfE+6IWcbz/ce++9wZ8HDx6s5ORkjR07Vrt27VLfvn2bus1GNfuX4Lp37662bduecxVLTU2NkpKSjLpqHrp27aqrrrpKFRUV1q2Y+fYY4Pg4V3p6urp3794qj48ZM2bovffe08cffxzy/WFJSUk6efKkDh8+HDK/tR4P59sPjcnIyJCkZnU8NPsAiomJ0bBhw7R+/frgsoaGBq1fv16ZmZmGndk7evSodu3apeTkZOtWzKSlpSkpKSnk+AgEAtqyZctlf3zs27dPtbW1rer4cBxHM2bM0KpVq7RhwwalpaWFrB82bJjat28fcjyUlZVpz549rep4uNh+aMz27dslqXkdD9ZXQXwfb731luP1ep2ioiLnv//9r3Pvvfc6Xbt2daqrq61ba1K//vWvneLiYqeystL5xz/+4WRnZzvdu3d3Dhw4YN1aVB05csT57LPPnM8++8yR5Dz77LPOZ5995nz55ZeO4zjO008/7XTt2tVZs2aNs2PHDmfixIlOWlqac/z4cePOI+tC++HIkSPOQw895JSWljqVlZXOunXrnB/+8IdO//79nRMnTli3HjHTp093fD6fU1xc7FRVVQXHsWPHgnOmTZvm9OrVy9mwYYOzdetWJzMz08nMzDTsOvIuth8qKiqcBQsWOFu3bnUqKyudNWvWOOnp6c7o0aONOw/VIgLIcRznhRdecHr16uXExMQ4I0aMcDZv3mzdUpO77bbbnOTkZCcmJsa58sorndtuu82pqKiwbivqPv74Y0fSOWPKlCmO45y5FHvOnDlOYmKi4/V6nbFjxzplZWW2TUfBhfbDsWPHnHHjxjk9evRw2rdv7/Tu3duZOnVqq/tPWmO/vyRn6dKlwTnHjx937rvvPueKK65wOnXq5EyaNMmpqqqyazoKLrYf9uzZ44wePdqJj493vF6v069fP+fhhx92/H6/bePfwfcBAQBMNPv3gAAArRMBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPwf0EAxNZXmhTIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Accuracy is 0.10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, b1, b2, A2\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m W1, W2, b1, b2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# use a smaller learning rate and more iterations\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Final predictions and accuracy\u001b[39;00m\n\u001b[0;32m    101\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n",
      "Cell \u001b[1;32mIn[6], line 84\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(x, y_one_hot, y, alpha, iterations)\u001b[0m\n\u001b[0;32m     81\u001b[0m L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m for_pass(W1, W2, b1, b2)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m dL2, dW2, db2, dL1, dW1, db1 \u001b[38;5;241m=\u001b[39m \u001b[43mback_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     87\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m, in \u001b[0;36mback_pass\u001b[1;34m(L2, A2, y_one_hot, W2, A1, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m db2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dL2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m# gradient of the bias in the second layer\u001b[39;00m\n\u001b[0;32m     55\u001b[0m dL1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W2\u001b[38;5;241m.\u001b[39mT, dL2) \u001b[38;5;241m*\u001b[39m (A1 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# error in the first layer with ReLU derivative\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m dW1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdL1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m# gradient of the weights in the first layer\u001b[39;00m\n\u001b[0;32m     57\u001b[0m db1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dL1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m# gradient of the bias in the first layer\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dL2, dW2, db2, dL1, dW1, db1\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "data = pd.read_csv('train.csv') #MNIST DATASET from kaggle\n",
    "\n",
    "# Extracting the pixel values and labels\n",
    "x = data.iloc[:,1:].values.T / 255.0  # extracting the pixel value and normalizing\n",
    "y = data.iloc[:,0].values.T   # extracting the labels in the first column\n",
    "m, n = data.shape\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_one_hot = np.eye(10)[y].T\n",
    "\n",
    "# Function to display a random image along with its label\n",
    "def image(a):\n",
    "    a = np.random.randint(0, m)\n",
    "    plt.imshow(x[:, a].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Label : {}\".format(y[a]))\n",
    "    plt.show()\n",
    "\n",
    "# Display a random image\n",
    "img = image(0)\n",
    "\n",
    "# Initialize parameters\n",
    "def parameters() :\n",
    "    W1 = np.random.randn(128,784) * np.sqrt(2./784)   # He initialization\n",
    "    W2 = np.random.randn(10,128) * np.sqrt(2./128)\n",
    "    b1 = np.zeros((128,1))  # initialize biases to zero\n",
    "    b2 = np.zeros((10,1))\n",
    "    return W1, W2, b1, b2\n",
    "\n",
    "# Activation functions\n",
    "def RELU(x):\n",
    "    return np.maximum(0, x) # rectified linear unit\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))  # for numerical stability\n",
    "    return exp_x / np.sum(exp_x, axis=0, keepdims=True) # softmax function\n",
    "\n",
    "# Forward pass\n",
    "def for_pass(W1, W2, b1, b2) :\n",
    "    L1 = np.dot(W1, x) + b1 # first layer\n",
    "    A1 = RELU(L1) # activation function\n",
    "    L2 = np.dot(W2, A1) + b2 # second layer\n",
    "    A2 = softmax(L2) # activation function\n",
    "    return L1, A1, L2, A2\n",
    "\n",
    "# Backward pass\n",
    "def back_pass(L2, A2, y_one_hot, W2, A1, x) :\n",
    "    dL2 = A2 - y_one_hot # error in the second layer\n",
    "    dW2 = np.dot(dL2, A1.T)/m # gradient of the weights in the second layer\n",
    "    db2 = np.sum(dL2, axis=1, keepdims=True)/m # gradient of the bias in the second layer\n",
    "    dL1 = np.dot(W2.T, dL2) * (A1 > 0) # error in the first layer with ReLU derivative\n",
    "    dW1 = np.dot(dL1, x.T)/m # gradient of the weights in the first layer\n",
    "    db1 = np.sum(dL1, axis=1, keepdims=True)/m # gradient of the bias in the first layer\n",
    "    return dL2, dW2, db2, dL1, dW1, db1\n",
    "\n",
    "# Update weights\n",
    "def weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha) :\n",
    "    W1 = W1 - alpha*dW1    # alpha is the learning rate\n",
    "    W2 = W2 - alpha*dW2\n",
    "    b1 = b1 - alpha*db1\n",
    "    b2 = b2 - alpha*db2\n",
    "    return W1, W2, b1, b2\n",
    "\n",
    "# Get predictions\n",
    "def get_predictions(A2) :\n",
    "    return np.argmax(A2, 0) # returns the index of the maximum value in the array\n",
    "\n",
    "# Get accuracy\n",
    "def get_accuracy(predictions, y) :\n",
    "    return np.sum(predictions == y)/m # returns the accuracy of the model\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(x, y_one_hot, y, alpha, iterations):\n",
    "    W1, W2, b1, b2 = parameters()\n",
    "    for i in range(iterations):\n",
    "        # Forward pass\n",
    "        L1, A1, L2, A2 = for_pass(W1, W2, b1, b2)\n",
    "        \n",
    "        # Backward pass\n",
    "        dL2, dW2, db2, dL1, dW1, db1 = back_pass(L2, A2, y_one_hot, W2, A1, x)\n",
    "        \n",
    "        # Update weights\n",
    "        W1, W2, b1, b2 = weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
    "        \n",
    "        # Monitor training progress\n",
    "        predictions = get_predictions(A2)\n",
    "        accuracy = get_accuracy(predictions, y)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Accuracy is {accuracy:.2f}\")\n",
    "    \n",
    "    return W1, W2, b1, b2, A2\n",
    "\n",
    "# Example usage:\n",
    "W1, W2, b1, b2, A2 = gradient_descent(x, y_one_hot, y, 0.01, 5000)  # use a smaller learning rate and more iterations\n",
    "\n",
    "# Final predictions and accuracy\n",
    "predictions = get_predictions(A2)\n",
    "accuracy = get_accuracy(predictions, y)\n",
    "print(f\"Final accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
