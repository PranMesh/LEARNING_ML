{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGIT RECOGNIZING - MNIST DATAASET (No pytorch/tf, just NUMPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE MNIST DATASET WAS DOWNLOADED FROM KAGGLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv') #MNIST DATASET from kaggle\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #we have 42000 images and 785 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data) #shuffling the data\n",
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 42000)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "x = data[:, 1:].T/255.0  # extracting the pixel value \n",
    "y = data[:, 0]   # extracting the labels in the first column\n",
    "m, n = data.shape\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGIT RECOGNIZING - MNIST DATAASET (No pytorch/tf, just NUMPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def image(a):\n",
    "    a = np.random.randint(0, m)\n",
    "    plt.imshow(x[:, a].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Label : {}\".format(y[a]))\n",
    "    plt.show()\n",
    "#random image along with its label\n",
    "img = image(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 42000)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot encoding\n",
    "def one_hot(y):\n",
    "    one_hot_y = np.zeros((10, y.size))\n",
    "    for i in range(y.size):\n",
    "        one_hot_y[y[i], i] = 1\n",
    "    return one_hot_y\n",
    "one_hot_y = one_hot(y)\n",
    "one_hot_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784) (10, 10) (10, 42000) (10, 42000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((784, 42000), (10, 42000))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def parameters() :\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W1 = np.random.randn(10, 784) - 0.5   # adding bias to the weights\n",
    "        self.W2 = np.random.randn(10, 10) - 0.5\n",
    "        self.b1 = np.zeros((10,m)) - 0.5\n",
    "        self.b2 = np.zeros((10, m)) - 0.5  \n",
    "        self.alpha  = 0.1    # learning rate\n",
    "params = Parameters()\n",
    "W1 = params.W1\n",
    "W2 = params.W2\n",
    "b1 = params.b1\n",
    "b2 = params.b2\n",
    "alpha = params.alpha\n",
    "        \n",
    "\n",
    "print(W1.shape, W2.shape, b1.shape, b2.shape)\n",
    "x.shape, one_hot_y.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTIVATION FUNCTIONS \n",
    " \n",
    "def RELU(L):\n",
    "    return np.maximum(0, L) #rectified linear unit\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0) #softmax function\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_pass(W1, W2, b1, b2, x):\n",
    "    L1 = np.dot(W1, x) + b1 #first layer\n",
    "    A1 = RELU(L1) #activation function\n",
    "    L2 = np.dot(W2, A1) + b2 #second layer\n",
    "    A2 = softmax(L2) #activation function\n",
    "    return L1, A1, L2, A2\n",
    "\n",
    "\n",
    "\n",
    "L1, A1, L2, A2 = for_pass(W1, W2, b1, b2, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der_Relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_pass(L2, A2, one_hot_y, W2, A1, x, L1):\n",
    "    dL2 = A2 - one_hot_y #error in the second layer\n",
    "    dW2 = np.dot(dL2, A1.T)/m #gradient of the weights in the second layer\n",
    "    db2 = np.sum(dL2, axis=1, keepdims=True)/m #gradient of the bias in the second layer\n",
    "    dL1 = np.dot(W2.T, dL2) * der_Relu(L1) #error in the first layer\n",
    "    dW1 = np.dot(dL1, x.T)/m #gradient of the weights in the first layer\n",
    "    db1 = np.sum(dL1, axis=1, keepdims=True)/m #gradient of the bias in the first layer\n",
    "    return dL2, dW2, db2, dL1, dW1, db1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha) :\n",
    "    #alpha = 0.01\n",
    "    W1 = W1 - alpha*dW1    #aplha is the learning rate\n",
    "    W2 = W2 - alpha*dW2\n",
    "    b1 = b1 - alpha*db1\n",
    "    b2 = b2 - alpha*db2\n",
    "    return W1, W2, b1, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2) :\n",
    "    return np.argmax(A2, 0) #returns the index of the maximum value in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, y):\n",
    "    return np.sum(predictions == y) / y.size  # returns the accuracy of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.09838095238095237\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[239], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m            \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, b1, b2\n\u001b[1;32m---> 21\u001b[0m W1, W2, b1, b2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m for_pass(W1, W2, b1, b2, x)\n\u001b[0;32m     23\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n",
      "Cell \u001b[1;32mIn[239], line 11\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(x, one_hot_y, alpha, iterations)\u001b[0m\n\u001b[0;32m      9\u001b[0m L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m for_pass(W1, W2, b1, b2, x)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#backward pass \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m dL2, dW2, db2, dL1, dW1, db1 \u001b[38;5;241m=\u001b[39m \u001b[43mback_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#weight update\u001b[39;00m\n\u001b[0;32m     13\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
      "Cell \u001b[1;32mIn[234], line 6\u001b[0m, in \u001b[0;36mback_pass\u001b[1;34m(L2, A2, one_hot_y, W2, A1, x, L1)\u001b[0m\n\u001b[0;32m      4\u001b[0m db2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dL2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m#gradient of the bias in the second layer\u001b[39;00m\n\u001b[0;32m      5\u001b[0m dL1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W2\u001b[38;5;241m.\u001b[39mT, dL2) \u001b[38;5;241m*\u001b[39m der_Relu(L1) \u001b[38;5;66;03m#error in the first layer\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dW1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdL1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m#gradient of the weights in the first layer\u001b[39;00m\n\u001b[0;32m      7\u001b[0m db1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dL1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m#gradient of the bias in the first layer\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dL2, dW2, db2, dL1, dW1, db1\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gradient_descent(x, one_hot_y, alpha, iterations):\n",
    "    #W1, W2, b1, b2 = parameters()\n",
    "    W1 = params.W1\n",
    "    W2 = params.W2\n",
    "    b1 = params.b1\n",
    "    b2 = params.b2\n",
    "    for i in range(iterations):\n",
    "        #forward pass\n",
    "        L1, A1, L2, A2 = for_pass(W1, W2, b1, b2, x)\n",
    "        #backward pass \n",
    "        dL2, dW2, db2, dL1, dW1, db1 = back_pass(L2, A2, one_hot_y, W2, A1, x, L1)\n",
    "        #weight update\n",
    "        W1, W2, b1, b2 = weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
    "        #acalculating accuracy\n",
    "        predictions = get_predictions(A2)\n",
    "        accuracy = get_accuracy(predictions, y)\n",
    "        if i % 100 == 0:\n",
    "           print(f\"accuracy is {accuracy}\")\n",
    "    return W1, W2, b1, b2\n",
    "            \n",
    "W1, W2, b1, b2, A2 = gradient_descent(x, one_hot_y, 0.01, 1000)\n",
    "L1, A1, L2, A2 = for_pass(W1, W2, b1, b2, x)\n",
    "predictions = get_predictions(A2)\n",
    "accuracy = get_accuracy(predictions, y)\n",
    "print(f\"accuracy is {accuracy}\") \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Accuracy is 0.10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m W1, W2, b1, b2, A2\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m W1, W2, b1, b2, A2 \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# use a smaller learning rate and more iterations\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Final predictions and accuracy\u001b[39;00m\n\u001b[0;32m    101\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_predictions(A2)\n",
      "Cell \u001b[1;32mIn[6], line 84\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(x, y_one_hot, y, alpha, iterations)\u001b[0m\n\u001b[0;32m     81\u001b[0m L1, A1, L2, A2 \u001b[38;5;241m=\u001b[39m for_pass(W1, W2, b1, b2)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m dL2, dW2, db2, dL1, dW1, db1 \u001b[38;5;241m=\u001b[39m \u001b[43mback_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     87\u001b[0m W1, W2, b1, b2 \u001b[38;5;241m=\u001b[39m weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m, in \u001b[0;36mback_pass\u001b[1;34m(L2, A2, y_one_hot, W2, A1, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m db2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dL2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m# gradient of the bias in the second layer\u001b[39;00m\n\u001b[0;32m     55\u001b[0m dL1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W2\u001b[38;5;241m.\u001b[39mT, dL2) \u001b[38;5;241m*\u001b[39m (A1 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# error in the first layer with ReLU derivative\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m dW1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdL1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m# gradient of the weights in the first layer\u001b[39;00m\n\u001b[0;32m     57\u001b[0m db1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dL1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mm \u001b[38;5;66;03m# gradient of the bias in the first layer\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dL2, dW2, db2, dL1, dW1, db1\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "data = pd.read_csv('train.csv') #MNIST DATASET from kaggle\n",
    "\n",
    "# Extracting the pixel values and labels\n",
    "x = data.iloc[:,1:].values.T / 255.0  # extracting the pixel value and normalizing\n",
    "y = data.iloc[:,0].values.T   # extracting the labels in the first column\n",
    "m, n = data.shape\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_one_hot = np.eye(10)[y].T\n",
    "\n",
    "# Function to display a random image along with its label\n",
    "def image(a):\n",
    "    a = np.random.randint(0, m)\n",
    "    plt.imshow(x[:, a].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Label : {}\".format(y[a]))\n",
    "    plt.show()\n",
    "\n",
    "# Display a random image\n",
    "img = image(0)\n",
    "\n",
    "# Initialize parameters\n",
    "def parameters() :\n",
    "    W1 = np.random.randn(128,784) * np.sqrt(2./784)   # He initialization\n",
    "    W2 = np.random.randn(10,128) * np.sqrt(2./128)\n",
    "    b1 = np.zeros((128,1))  # initialize biases to zero\n",
    "    b2 = np.zeros((10,1))\n",
    "    return W1, W2, b1, b2\n",
    "\n",
    "# Activation functions\n",
    "def RELU(x):\n",
    "    return np.maximum(0, x) # rectified linear unit\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))  # for numerical stability\n",
    "    return exp_x / np.sum(exp_x, axis=0, keepdims=True) # softmax function\n",
    "\n",
    "# Forward pass\n",
    "def for_pass(W1, W2, b1, b2) :\n",
    "    L1 = np.dot(W1, x) + b1 # first layer\n",
    "    A1 = RELU(L1) # activation function\n",
    "    L2 = np.dot(W2, A1) + b2 # second layer\n",
    "    A2 = softmax(L2) # activation function\n",
    "    return L1, A1, L2, A2\n",
    "\n",
    "# Backward pass\n",
    "def back_pass(L2, A2, y_one_hot, W2, A1, x) :\n",
    "    dL2 = A2 - y_one_hot # error in the second layer\n",
    "    dW2 = np.dot(dL2, A1.T)/m # gradient of the weights in the second layer\n",
    "    db2 = np.sum(dL2, axis=1, keepdims=True)/m # gradient of the bias in the second layer\n",
    "    dL1 = np.dot(W2.T, dL2) * (A1 > 0) # error in the first layer with ReLU derivative\n",
    "    dW1 = np.dot(dL1, x.T)/m # gradient of the weights in the first layer\n",
    "    db1 = np.sum(dL1, axis=1, keepdims=True)/m # gradient of the bias in the first layer\n",
    "    return dL2, dW2, db2, dL1, dW1, db1\n",
    "\n",
    "# Update weights\n",
    "def weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha) :\n",
    "    W1 = W1 - alpha*dW1    # alpha is the learning rate\n",
    "    W2 = W2 - alpha*dW2\n",
    "    b1 = b1 - alpha*db1\n",
    "    b2 = b2 - alpha*db2\n",
    "    return W1, W2, b1, b2\n",
    "\n",
    "# Get predictions\n",
    "def get_predictions(A2) :\n",
    "    return np.argmax(A2, 0) # returns the index of the maximum value in the array\n",
    "\n",
    "# Get accuracy\n",
    "def get_accuracy(predictions, y) :\n",
    "    return np.sum(predictions == y)/m # returns the accuracy of the model\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(x, y_one_hot, y, alpha, iterations):\n",
    "    W1, W2, b1, b2 = parameters()\n",
    "    for i in range(iterations):\n",
    "        # Forward pass\n",
    "        L1, A1, L2, A2 = for_pass(W1, W2, b1, b2)\n",
    "        \n",
    "        # Backward pass\n",
    "        dL2, dW2, db2, dL1, dW1, db1 = back_pass(L2, A2, y_one_hot, W2, A1, x)\n",
    "        \n",
    "        # Update weights\n",
    "        W1, W2, b1, b2 = weight_update(W1, W2, b1, b2, dW1, dW2, db1, db2, alpha)\n",
    "        \n",
    "        # Monitor training progress\n",
    "        predictions = get_predictions(A2)\n",
    "        accuracy = get_accuracy(predictions, y)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Accuracy is {accuracy:.2f}\")\n",
    "    \n",
    "    return W1, W2, b1, b2, A2\n",
    "\n",
    "# Example usage:\n",
    "W1, W2, b1, b2, A2 = gradient_descent(x, y_one_hot, y, 0.01, 5000)  # use a smaller learning rate and more iterations\n",
    "\n",
    "# Final predictions and accuracy\n",
    "predictions = get_predictions(A2)\n",
    "accuracy = get_accuracy(predictions, y)\n",
    "print(f\"Final accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
